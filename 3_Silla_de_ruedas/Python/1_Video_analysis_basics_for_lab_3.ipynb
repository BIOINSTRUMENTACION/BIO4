{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Base Generation\n",
    "\n",
    "###  Basic Frame Capture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is just an example to ilustrate how to display video from webcam##\n",
    "vid = cv2.VideoCapture(0)      # define a video capture object \n",
    "status = True                  # Initalize status\n",
    "while(status):                 # Iterate while status is true, that is while there is a frame being captured\n",
    "    status, frame = vid.read() # Capture the video frame by frame, returns status (Boolean) and frame (numpy.ndarray)\n",
    "    cv2.imshow('frame', frame) # Display the resulting frame \n",
    "    \n",
    "    ## Exit if user presses q ##\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "vid.release()              # After the loop release the cap object \n",
    "cv2.destroyAllWindows()    # Destroy all the windows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Screenshots  off of Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is just an example to ilustrate how to capture frames from webcam ##\n",
    "path = \"Bounding_box\"              # Name of folder where information will be stored\n",
    "frame_id = 0                       # Id of image\n",
    "vid = cv2.VideoCapture(0)          # define a video capture object \n",
    "status = True                      # Initalize status\n",
    "while(status):                     # Iterate while status is True\n",
    "    status, frame = vid.read()     # Capture the video frame by frame \n",
    "    cv2.imshow('frame', frame)     # Display the resulting frame \n",
    "    wait_key=cv2.waitKey(1) & 0xFF # Save Waitkey object in variable since we will use it multiple times\n",
    "    if  wait_key  == ord('a'):     # If a is pressed\n",
    "        name =\"eye\"+str(frame_id)+'.jpg' \n",
    "        name = path + \"\\\\\" + name  # Set name and path\n",
    "        cv2.imwrite(name, frame)   # Save image\n",
    "        frame_id += 1              # Incremente frame_id\n",
    "        \n",
    "        \n",
    "    elif wait_key  == ord('q'):    # If user press \"q\" \n",
    "        break                      # Exit from while Loop\n",
    "  \n",
    " \n",
    "vid.release()                      # After the loop release the cap object \n",
    "cv2.destroyAllWindows()            # Destroy all the windows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Haar Cascade to detect objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is just an example to ilustrate how to use Haar Cascades in order to detect objects (LIVE) ##\n",
    "face = cv2.CascadeClassifier('Haarcascade/haarcascade_frontalface_default.xml') # Face Haar Cascade loading\n",
    "eye = cv2.CascadeClassifier('Haarcascade/haarcascade_eye.xml')                  # Eye  Haar Cascade Loading\n",
    "path = \"Bounding_box\"                                                           # Path to Store Photos\n",
    "frame_id = 0                                                                    # Frame Id\n",
    "vid = cv2.VideoCapture(0)                                                       # Define a video capture object \n",
    "status = True                                                                   # Initalize status\n",
    "while(status): \n",
    "    status, frame = vid.read()                             # Capture the video frame by frame \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)         # Convert to gray scale\n",
    "    face_info = face.detectMultiScale(gray, 1.3, 5)        # Get face infromation\n",
    "    for (x,y,w,h) in face_info:                            # Iterate over this information\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,255,0),1) # Draw rectangle\n",
    "        cropped_face = gray[y:y+h, x:x+w]                  # Crop face\n",
    "        eye_info = eye.detectMultiScale(gray)              # Get info of eyes\n",
    "        for (ex,ey,ew,eh)  in eye_info:                    # Iterate over eye information\n",
    "            cv2.rectangle(frame,(ex,ey),(ex+ew,ey+eh),(0,255,0),2) # Draw over eye information\n",
    "            \n",
    "    \n",
    "    cv2.imshow('frame', frame)             # Display the resulting frame \n",
    "    wait_key = cv2.waitKey(1) & 0xFF       # Store Waitkey object\n",
    "    if  wait_key  == ord('a'):             # If a is pressed\n",
    "        name = \"eye\"+str(frame_id)+'.jpg'  # Set name \n",
    "        name = path + \"\\\\\" + name          # Add path\n",
    "        cv2.imwrite(name, frame)           # Set  photo\n",
    "        frame_id += 1                      # Increment frame id\n",
    "        \n",
    "        \n",
    "    elif wait_key  == ord('q'):            # If q is pressed\n",
    "        break                              # Break while loop\n",
    "  \n",
    "    \n",
    "\n",
    "vid.release()              # After the loop release the cap object \n",
    "cv2.destroyAllWindows()    # Destroy all the windows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture face gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is just an example to ilustrate how to use Haar Cascades in order to detect objects (LIVE) ##\n",
    "face = cv2.CascadeClassifier('Haarcascade/haarcascade_frontalface_default.xml') # Face Haar Cascade loading\n",
    "eye = cv2.CascadeClassifier('Haarcascade/haarcascade_eye.xml')                  # Eye  Haar Cascade Loading\n",
    "path = \"Bouding_box\"                                                           # Path to Store Photos\n",
    "frame_id = 0                                                                   # Frame Id\n",
    "vid = cv2.VideoCapture(0)                                                       # Define a video capture object \n",
    "status = True                                                                   # Initalize status\n",
    "while(status): \n",
    "    status, frame = vid.read()                             # Capture the video frame by frame \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)         # Convert to gray scale\n",
    "    face_info = face.detectMultiScale(gray, 1.3, 5)        # Get face infromation\n",
    "    for (x,y,w,h) in face_info:                            # Iterate over this information\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,255,0),1) # Draw rectangle\n",
    "        cropped_face_color = frame[y:y+h, x:x+w]           # Crop face (color) \n",
    "    \n",
    "    \n",
    "    cv2.imshow('frame',  frame)  # Display the resulting frame \n",
    "    wait_key = cv2.waitKey(1) & 0xFF          # Store Waitkey object\n",
    "    if  wait_key  == ord('a'):                # If a is pressed\n",
    "        name = \"eye\"+str(frame_id)+'.jpg'     # Set name \n",
    "        name = path + \"\\\\\" + name             # Add path\n",
    "        cv2.imwrite(name, cropped_face_color) # Set  photo\n",
    "        frame_id += 1                         # Increment frame id\n",
    "        \n",
    "        \n",
    "    elif wait_key  == ord('q'):            # If q is pressed\n",
    "        break                              # Break while loop\n",
    "  \n",
    "    \n",
    "\n",
    "vid.release()              # After the loop release the cap object \n",
    "cv2.destroyAllWindows()    # Destroy all the windows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
